{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f987fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35573785-c10e-4dd5-a0b0-c72515108d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.34992686,  3.74868762,  2.24346025, ...,  3.60797491,\n",
       "         4.12885474,  4.67721877],\n",
       "       [-1.60123924, -1.55323331, -1.41290443, ...,  0.49439067,\n",
       "         0.53462193,  0.54836403],\n",
       "       [ 0.04800593,  0.0941674 ,  0.18101182, ...,  0.05185166,\n",
       "         0.02698668,  0.0137421 ],\n",
       "       [ 0.04616147,  0.06650295,  0.07977621, ..., -0.02283558,\n",
       "        -0.01905478, -0.01324458]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df1 = pd.read_csv('DownSampling/PPG_ds/ppg_signal_01_0001.csv')\n",
    "data_df1.to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bb82a6-e2de-4de1-9aaa-d2d12bb9cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "fiducials_signal_01_0001.csv\n",
      "fiducials_signal_01_0002.csv\n",
      "1\n",
      "fiducials_signal_01_0002.csv\n",
      "fiducials_signal_01_0003.csv\n",
      "fiducials_signal_01_0004.csv\n",
      "fiducials_signal_01_0005.csv\n",
      "fiducials_signal_01_0006.csv\n",
      "fiducials_signal_01_0007.csv\n",
      "fiducials_signal_02_0001.csv\n",
      "fiducials_signal_02_0002.csv\n",
      "fiducials_signal_02_0003.csv\n",
      "fiducials_signal_03_0001.csv\n",
      "fiducials_signal_03_0002.csv\n",
      "fiducials_signal_04_0001.csv\n",
      "fiducials_signal_04_0002.csv\n",
      "fiducials_signal_04_0003.csv\n",
      "14\n",
      "fiducials_signal_04_0003.csv\n",
      "fiducials_signal_04_0004.csv\n",
      "fiducials_signal_04_0005.csv\n",
      "16\n",
      "fiducials_signal_04_0005.csv\n",
      "fiducials_signal_05_0001.csv\n",
      "fiducials_signal_05_0002.csv\n",
      "fiducials_signal_05_0003.csv\n",
      "fiducials_signal_05_0004.csv\n",
      "fiducials_signal_05_0005.csv\n",
      "fiducials_signal_05_0006.csv\n",
      "fiducials_signal_06_0001.csv\n",
      "23\n",
      "fiducials_signal_06_0001.csv\n",
      "fiducials_signal_06_0002.csv\n",
      "fiducials_signal_07_0001.csv\n",
      "fiducials_signal_07_0002.csv\n",
      "fiducials_signal_07_0003.csv\n",
      "fiducials_signal_07_0004.csv\n",
      "fiducials_signal_08_0001.csv\n",
      "fiducials_signal_08_0002.csv\n",
      "fiducials_signal_09_0001.csv\n",
      "fiducials_signal_09_0002.csv\n",
      "32\n",
      "fiducials_signal_09_0002.csv\n",
      "fiducials_signal_10_0001.csv\n",
      "fiducials_signal_10_0002.csv\n",
      "fiducials_signal_11_0001.csv\n",
      "fiducials_signal_11_0002.csv\n",
      "fiducials_signal_11_0003.csv\n",
      "fiducials_signal_11_0004.csv\n",
      "fiducials_signal_12_0001.csv\n",
      "fiducials_signal_13_0001.csv\n",
      "fiducials_signal_13_0002.csv\n",
      "fiducials_signal_14_0001.csv\n",
      "fiducials_signal_14_0002.csv\n",
      "fiducials_signal_15_0001.csv\n",
      "fiducials_signal_15_0002.csv\n",
      "fiducials_signal_15_0003.csv\n",
      "fiducials_signal_16_0001.csv\n",
      "fiducials_signal_16_0002.csv\n",
      "fiducials_signal_16_0003.csv\n",
      "49\n",
      "fiducials_signal_16_0003.csv\n",
      "fiducials_signal_17_0001.csv\n",
      "fiducials_signal_17_0002.csv\n",
      "fiducials_signal_18_0001.csv\n",
      "fiducials_signal_18_0002.csv\n",
      "fiducials_signal_18_0003.csv\n",
      "fiducials_signal_19_0001.csv\n",
      "fiducials_signal_19_0002.csv\n",
      "fiducials_signal_20_0001.csv\n",
      "fiducials_signal_20_0002.csv\n",
      "fiducials_signal_20_0003.csv\n",
      "fiducials_signal_21_0001.csv\n",
      "fiducials_signal_21_0002.csv\n",
      "fiducials_signal_22_0001.csv\n",
      "fiducials_signal_22_0002.csv\n",
      "fiducials_signal_22_0003.csv\n",
      "fiducials_signal_23_0001.csv\n",
      "fiducials_signal_23_0002.csv\n"
     ]
    }
   ],
   "source": [
    "d_list = []\n",
    "nan_index = []\n",
    "counter = 0\n",
    "#data_dir ='DownSampling/PPG_ds/'\n",
    "data_dir ='data/'\n",
    "for dir in os.listdir(data_dir):\n",
    "    print(dir)\n",
    "    if dir == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    df = pd.read_csv(data_dir+dir)\n",
    "    counter+=1\n",
    "    if df.isnull().values.any():\n",
    "        print(counter-1)\n",
    "        nan_index.append(counter-1)\n",
    "        print(dir)\n",
    "        continue\n",
    "    d_list.append(df.values.tolist()[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d317ba4e-9977-4509-a70b-c21111308912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Glucose_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>38</td>\n",
       "      <td>99</td>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>38</td>\n",
       "      <td>102</td>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>38</td>\n",
       "      <td>103</td>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>38</td>\n",
       "      <td>128</td>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>38</td>\n",
       "      <td>130</td>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>38</td>\n",
       "      <td>134</td>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>38</td>\n",
       "      <td>136</td>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>25</td>\n",
       "      <td>111</td>\n",
       "      <td>187</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>25</td>\n",
       "      <td>108</td>\n",
       "      <td>187</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>25</td>\n",
       "      <td>118</td>\n",
       "      <td>187</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>33</td>\n",
       "      <td>120</td>\n",
       "      <td>187</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>33</td>\n",
       "      <td>127</td>\n",
       "      <td>187</td>\n",
       "      <td>103</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>105</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>106</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>107</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>109</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>175</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>175</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>175</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Gender  Age  Glucose  Height  Weight  Glucose_Level\n",
       "0    1  'Male'   38       99     180      53              2\n",
       "1    1  'Male'   38      102     180      53              3\n",
       "2    1  'Male'   38      103     180      53              3\n",
       "3    1  'Male'   38      128     180      53              6\n",
       "4    1  'Male'   38      130     180      53              6\n",
       "5    1  'Male'   38      134     180      53              7\n",
       "6    1  'Male'   38      136     180      53              7\n",
       "7    2  'Male'   25      111     187      75              5\n",
       "8    2  'Male'   25      108     187      75              4\n",
       "9    2  'Male'   25      118     187      75              5\n",
       "10   3  'Male'   33      120     187     103              5\n",
       "11   3  'Male'   33      127     187     103              6\n",
       "12   4  'Male'   29      100     180      80              2\n",
       "13   4  'Male'   29      105     180      80              3\n",
       "14   4  'Male'   29      106     180      80              4\n",
       "15   4  'Male'   29      107     180      80              4\n",
       "16   4  'Male'   29      109     180      80              4\n",
       "17   5  'Male'   23      106     175      56              4\n",
       "18   5  'Male'   23       94     175      56              1\n",
       "19   5  'Male'   23       96     175      56              2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv('labels_final (2).csv')\n",
    "label_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ad7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_df.drop(nan_index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3950c994-628b-4daf-a73b-e04f06f82de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71947bb8-037b-433d-a44b-7d15ca42a245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd44a13-3553-4420-bae0-176fa304f944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_df['Glucose_Level'].hist(bins =8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f319f82-fca7-4924-8248-a5504d2655ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = label_df[label_df['Glucose_Level'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48e2f10b-f651-4a4e-8ba8-e51a89a88218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e27c6446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Glucose_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>33</td>\n",
       "      <td>127</td>\n",
       "      <td>187</td>\n",
       "      <td>103</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>105</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>29</td>\n",
       "      <td>107</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>'Male'</td>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>175</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Gender  Age  Glucose  Height  Weight  Glucose_Level\n",
       "11   3  'Male'   33      127     187     103              6\n",
       "12   4  'Male'   29      100     180      80              2\n",
       "13   4  'Male'   29      105     180      80              3\n",
       "15   4  'Male'   29      107     180      80              4\n",
       "17   5  'Male'   23      106     175      56              4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.iloc[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9122aa74-7a09-4066-ba81-8b5f36e1a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "df_encoded = pd.get_dummies(label_df['Glucose_Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f7f47-8201-4c36-9706-23ad57b70d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a252b7c4-cb61-40b6-bc95-a926cbda03db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 5, 6, 4, 3, 0, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows  \n",
    "label_encoder = preprocessing.LabelEncoder()  \n",
    "label_df['Glucose_Level']= label_encoder.fit_transform(label_df['Glucose_Level']) \n",
    "  \n",
    "label_df['Glucose_Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9978c9b-a4bb-4b51-b8e2-27dcfbc3c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "2     2\n",
       "3     5\n",
       "4     5\n",
       "5     6\n",
       "     ..\n",
       "62    5\n",
       "63    3\n",
       "64    0\n",
       "65    1\n",
       "66    3\n",
       "Name: Glucose_Level, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df['Glucose_Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42af5b98-f61f-48e9-a90f-6b38e67a8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Glucose = label_df['Glucose'].to_numpy()\n",
    "#Glucose_level = label_df['Glucose_Level'].to_numpy()\n",
    "Glucose_level = df_encoded.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9529717-c345-47b4-b52e-5d86790de544",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, sub_x, y_train, sub_y = train_test_split(d_list, Glucose_level, test_size=0.30, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(sub_x, sub_y, test_size = 1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e53deefd-2cf7-494f-afcf-028451fb265d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "301ff0da-a45e-4f70-938a-75580211ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver data to tensors\n",
    "x_train_t = torch.tensor(X_train).float()\n",
    "x_val_t = torch.tensor(X_val).float()\n",
    "x_test_t = torch.tensor(X_test).float()\n",
    "y_train_t = torch.tensor(y_train).float()\n",
    "y_val_t = torch.tensor(y_val).float()\n",
    "#dataset \n",
    "train_tensor = TensorDataset(x_train_t,y_train_t)\n",
    "valid_tensor = TensorDataset(x_val_t,y_val_t)\n",
    "# dataloader\n",
    "dataloaders = dict()\n",
    "dataloaders[\"train\"] = DataLoader(train_tensor, batch_size=23, shuffle=True)\n",
    "dataloaders[\"val\"] = DataLoader(valid_tensor, batch_size=7)\n",
    "dataloaders[\"test\"] = DataLoader(x_test_t, batch_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d95402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdb0f0a8-5ebc-4e61-afd7-4e0ed8a53f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders['valid2'] =  DataLoader(x_val_t, batch_size=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04503c9a-fa96-45c8-9ba1-8cf64409b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders[\"test2\"] = DataLoader(x_train_t, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aee85543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_t.shape\n",
    "len(dataloaders[\"test2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d21a913-a20e-4acb-9c19-ed37e6595eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, seq_len, dropout=0.5, output_size=9):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # LSTM Layers\n",
    "        self.lstm_1 = nn.LSTM(input_size, hidden_size[0], num_layers=2,\n",
    "                              batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_2 = nn.LSTM(2 * hidden_size[0], hidden_size[1], num_layers=2,\n",
    "                              batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_sizes[1] * 2*9, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=dropout),\n",
    "            nn.Linear(1024, output_size),\n",
    "            ##nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM layers:\n",
    "        x1, _ = self.lstm_1(x)\n",
    "        x2, _ = self.lstm_2(x1)\n",
    "        \n",
    "        # Fully connected layers:\n",
    "        x = x2.reshape(x2.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "264b2564-6789-4a26-9dae-022c45ee363a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Definition of a RNN Model class\\nclass RNN(nn.Module):\\n    def __init__(self, input_size, hidden_sizes, seq_len, dropout=0.01, output_size=9):\\n        super(RNN, self).__init__()\\n        \\n        # LSTM Layers\\n        self.lstm_1 = nn.LSTM(input_size, hidden_sizes[0], num_layers=2,\\n                            batch_first=True, bidirectional=True, dropout=dropout)\\n        self.lstm_21 = nn.LSTM(2*hidden_sizes[0], hidden_sizes[1], num_layers=2,\\n                             batch_first=True, bidirectional=True, dropout=dropout)\\n        self.lstm_22 = nn.LSTM(input_size, hidden_sizes[1], num_layers=2,\\n                             batch_first=True, bidirectional=True, dropout=dropout)\\n        self.lstm_31 = nn.LSTM(2*hidden_sizes[1], hidden_sizes[2], num_layers=2,\\n                             batch_first=True, bidirectional=True, dropout=dropout)\\n        self.lstm_32 = nn.LSTM(4*hidden_sizes[1], hidden_sizes[2], num_layers=2,\\n                             batch_first=True, bidirectional=True, dropout=dropout)\\n        self.lstm_41 = nn.LSTM(2*hidden_sizes[2], hidden_sizes[3], num_layers=2,\\n                             batch_first=True, bidirectional=True, dropout=dropout)\\n        self.lstm_42 = nn.LSTM(4*hidden_sizes[2], hidden_sizes[3], num_layers=2,\\n                             batch_first=True, bidirectional=True, dropout=dropout)\\n        hidd = 2*hidden_sizes[0] + 4*(hidden_sizes[1]+hidden_sizes[2]+hidden_sizes[3])\\n        self.lstm_5 = nn.LSTM(hidd, hidden_sizes[4], num_layers=2,\\n                             batch_first=True, bidirectional=True, dropout=dropout)\\n        \\n        # Fully Connected Layer\\n        self.fc = nn.Sequential(nn.Linear(8*2*460, 4096),\\n                                nn.ReLU(),\\n                                nn.Dropout(p=dropout),\\n                                nn.Linear(4096, 1024),\\n                                nn.ReLU(),\\n                                nn.Dropout(p=dropout),\\n                                nn.Linear(1024, output_size),\\n                                nn.Softmax(dim =1)\\n                               )\\n        \\n    def forward(self, x):\\n        \\n        # lstm layers:\\n        x1, _ = self.lstm_1(x)\\n        \\n        x_x1, _ = self.lstm_21(x1)\\n        x_x2, _ = self.lstm_22(x)\\n        x2 = torch.cat([x_x1, x_x2], dim=2)\\n        \\n        x_x1, _ = self.lstm_31(x_x1)\\n        x_x2, _ = self.lstm_32(x2)\\n        x3 = torch.cat([x_x1, x_x2], dim=2)\\n        \\n        x_x1, _ = self.lstm_41(x_x1)\\n        x_x2, _ = self.lstm_42(x3)\\n        x4 = torch.cat([x_x1, x_x2], dim=2)\\n        x = torch.cat([x1, x2, x3, x4], dim=2)\\n        x, _ = self.lstm_5(x)\\n        \\n        # fully connected layers:\\n        x = x.reshape(x.shape[0], -1)\\n        x = self.fc(x)\\n        return x\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#more comlex model\n",
    "\n",
    "# Definition of a RNN Model class\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, seq_len, dropout=0.01, output_size=9):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # LSTM Layers\n",
    "        self.lstm_1 = nn.LSTM(input_size, hidden_sizes[0], num_layers=2,\n",
    "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_21 = nn.LSTM(2*hidden_sizes[0], hidden_sizes[1], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_22 = nn.LSTM(input_size, hidden_sizes[1], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_31 = nn.LSTM(2*hidden_sizes[1], hidden_sizes[2], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_32 = nn.LSTM(4*hidden_sizes[1], hidden_sizes[2], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_41 = nn.LSTM(2*hidden_sizes[2], hidden_sizes[3], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.lstm_42 = nn.LSTM(4*hidden_sizes[2], hidden_sizes[3], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        hidd = 2*hidden_sizes[0] + 4*(hidden_sizes[1]+hidden_sizes[2]+hidden_sizes[3])\n",
    "        self.lstm_5 = nn.LSTM(hidd, hidden_sizes[4], num_layers=2,\n",
    "                             batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Sequential(nn.Linear(8*2*460, 4096),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=dropout),\n",
    "                                nn.Linear(4096, 1024),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=dropout),\n",
    "                                nn.Linear(1024, output_size),\n",
    "                                nn.Softmax(dim =1)\n",
    "                               )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # lstm layers:\n",
    "        x1, _ = self.lstm_1(x)\n",
    "        \n",
    "        x_x1, _ = self.lstm_21(x1)\n",
    "        x_x2, _ = self.lstm_22(x)\n",
    "        x2 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        \n",
    "        x_x1, _ = self.lstm_31(x_x1)\n",
    "        x_x2, _ = self.lstm_32(x2)\n",
    "        x3 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        \n",
    "        x_x1, _ = self.lstm_41(x_x1)\n",
    "        x_x2, _ = self.lstm_42(x3)\n",
    "        x4 = torch.cat([x_x1, x_x2], dim=2)\n",
    "        x = torch.cat([x1, x2, x3, x4], dim=2)\n",
    "        x, _ = self.lstm_5(x)\n",
    "        \n",
    "        # fully connected layers:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fba536-bee7-420a-aeef-37cd9173b7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41ccf684-7695-4369-beff-59c2e78cb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALIDATION FUNCTION\n",
    "def validation(model, loader, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    preds_all = torch.LongTensor()\n",
    "    labels_all = torch.LongTensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, labels in loader:\n",
    "            labels_all = torch.cat((labels_all, labels), dim=0)\n",
    "            batch_x, labels = batch_x.to(device), labels.to(device)\n",
    "            labels = labels.float()\n",
    "            \n",
    "            output = model.forward(batch_x)\n",
    "            loss += criterion(output,torch.argmax(labels, dim=1)).item()\n",
    "            #loss += criterion(output,labels.long()).item()\n",
    "            preds_all = torch.cat((preds_all, output.to(\"cpu\")), dim=0)\n",
    "    total_loss = loss/len(loader)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7a5026d-666d-44a1-9c96-bb15947767ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "273bc60c-17a2-4fc6-9a4f-a44b060854ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " for batch_x, labels in dataloaders['train']:\n",
    "            labels = labels.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1ab1749-9808-4e5a-a3ae-3392f7e9da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING FUNCTION\n",
    "def train_model(model, trainloader, validloader, criterion, optimizer, \n",
    "                scheduler, epochs=20, device=\"cpu\", print_every=1):\n",
    "    model.to(device)\n",
    "    best_valid = 10\n",
    "    best_epoch = 0\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for batch_x, labels in trainloader:\n",
    "            batch_x, labels = batch_x.to(device), labels.to(device)\n",
    "            labels = labels.float()\n",
    "            \n",
    "            # Training \n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(batch_x)\n",
    "            loss = criterion(output, torch.argmax(labels, dim=1))\n",
    "            #loss = criterion(output, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        # at the end of each epoch calculate loss and auc score:\n",
    "        model.eval()\n",
    "        train_loss = validation(model, trainloader, criterion, device)\n",
    "        valid_loss = validation(model, validloader, criterion, device)\n",
    "        if valid_loss < best_valid:\n",
    "            best_valid = valid_loss\n",
    "            best_epoch = e\n",
    "            torch.save(model.state_dict(), \"best-state.pt\")\n",
    "        if e % print_every == 0:\n",
    "            to_print = \"Epoch: \"+str(e+1)+\" of \"+str(epochs)\n",
    "            to_print += \".. Train Loss: {:.4f}\".format(train_loss)\n",
    "            to_print += \".. Valid Loss: {:.4f}\".format(valid_loss)\n",
    "            to_print += \".. best Valid : {:.4f}\".format(best_valid)\n",
    "\n",
    "            print(to_print)\n",
    "    # After Training:\n",
    "    torch.save(model.state_dict(), \"best-state.pt\")\n",
    "    model.load_state_dict(torch.load(\"best-state.pt\"))\n",
    "    to_print = \"\\nTraining completed. Best state dict is loaded.\\n\"\n",
    "    print(to_print)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "067eb06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(d_list[1][1])\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b66778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_list[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe8c7b18-9873-4beb-aec8-8b4ed6995d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "RNN(\n",
      "  (lstm_1): LSTM(16, 1504, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (lstm_2): LSTM(3008, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=13824, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=1024, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sequence_length = len(x_train_t)\n",
    "input_size = len(d_list[1][1])\n",
    "#hidden_sizes = [192, 144, 96, 32,8]\n",
    "hidden_sizes = [376*2*2, 192*2*2, 144, 96,32]\n",
    "#hidden_sizes = [96,8]\n",
    "max_learning_rate = 0.001\n",
    "epochs = 50\n",
    "\n",
    "# Model\n",
    "model_lstm = RNN(input_size, hidden_sizes, sequence_length)\n",
    "print(\"Model: \")\n",
    "print(model_lstm)\n",
    "\n",
    "# criterion, optimizer, scheduler\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss() # in cass of useing remove the softmax layer CrossEntropyLoss() apply softmax automacly\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=max_learning_rate)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                          max_lr = max_learning_rate,\n",
    "                                          epochs = epochs + 1,\n",
    "                                          steps_per_epoch = int(len(dataloaders[\"train\"])),\n",
    "                                          pct_start = 0.2,\n",
    "                                          anneal_strategy = \"cos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2d1246a-fb0c-4132-94df-5f0610086a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled\n",
      "Epoch: 1 of 50.. Train Loss: 2.1814.. Valid Loss: 2.1785.. best Valid : 2.1785\n",
      "Epoch: 3 of 50.. Train Loss: 2.0723.. Valid Loss: 2.0883.. best Valid : 2.0883\n",
      "Epoch: 5 of 50.. Train Loss: 2.1267.. Valid Loss: 2.1223.. best Valid : 2.0883\n",
      "Epoch: 7 of 50.. Train Loss: 2.1106.. Valid Loss: 2.1097.. best Valid : 2.0354\n",
      "Epoch: 9 of 50.. Train Loss: 2.0569.. Valid Loss: 2.0342.. best Valid : 2.0342\n",
      "Epoch: 11 of 50.. Train Loss: 2.1954.. Valid Loss: 2.1628.. best Valid : 2.0342\n",
      "Epoch: 13 of 50.. Train Loss: 2.1841.. Valid Loss: 2.1142.. best Valid : 2.0342\n",
      "Epoch: 15 of 50.. Train Loss: 2.0977.. Valid Loss: 2.0836.. best Valid : 2.0342\n",
      "Epoch: 17 of 50.. Train Loss: 2.0774.. Valid Loss: 2.0551.. best Valid : 2.0290\n",
      "Epoch: 19 of 50.. Train Loss: 2.0904.. Valid Loss: 2.1129.. best Valid : 2.0290\n",
      "Epoch: 21 of 50.. Train Loss: 2.0616.. Valid Loss: 2.0470.. best Valid : 2.0290\n",
      "Epoch: 23 of 50.. Train Loss: 2.0634.. Valid Loss: 2.0172.. best Valid : 2.0172\n",
      "Epoch: 25 of 50.. Train Loss: 2.0692.. Valid Loss: 2.0171.. best Valid : 2.0138\n",
      "Epoch: 27 of 50.. Train Loss: 2.0613.. Valid Loss: 2.0399.. best Valid : 2.0138\n",
      "Epoch: 29 of 50.. Train Loss: 2.0724.. Valid Loss: 2.0460.. best Valid : 2.0138\n",
      "Epoch: 31 of 50.. Train Loss: 2.0733.. Valid Loss: 2.0399.. best Valid : 2.0138\n",
      "Epoch: 33 of 50.. Train Loss: 2.0560.. Valid Loss: 2.0301.. best Valid : 2.0138\n",
      "Epoch: 35 of 50.. Train Loss: 2.0643.. Valid Loss: 2.0306.. best Valid : 2.0138\n",
      "Epoch: 37 of 50.. Train Loss: 2.0561.. Valid Loss: 2.0341.. best Valid : 2.0138\n",
      "Epoch: 39 of 50.. Train Loss: 2.0599.. Valid Loss: 2.0369.. best Valid : 2.0138\n",
      "Epoch: 41 of 50.. Train Loss: 2.0601.. Valid Loss: 2.0362.. best Valid : 2.0138\n",
      "Epoch: 43 of 50.. Train Loss: 2.0588.. Valid Loss: 2.0366.. best Valid : 2.0138\n",
      "Epoch: 45 of 50.. Train Loss: 2.0502.. Valid Loss: 2.0361.. best Valid : 2.0138\n",
      "Epoch: 47 of 50.. Train Loss: 2.0587.. Valid Loss: 2.0358.. best Valid : 2.0138\n",
      "Epoch: 49 of 50.. Train Loss: 2.0467.. Valid Loss: 2.0356.. best Valid : 2.0138\n",
      "\n",
      "Training completed. Best state dict is loaded.\n",
      "\n",
      "CPU times: total: 14min 56s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    my_device = \"cpu\"\n",
    "    print(\"GPU is enabled\")\n",
    "else:\n",
    "    my_device = \"cpu\"\n",
    "    print(\"No GPU :(\")\n",
    "\n",
    "# Training\n",
    "train_model(model = model_lstm,\n",
    "            trainloader = dataloaders[\"train\"],\n",
    "            validloader = dataloaders[\"val\"],\n",
    "            criterion = criterion,\n",
    "            optimizer = optimizer,\n",
    "            scheduler = scheduler,\n",
    "            epochs = epochs,\n",
    "            device = my_device,\n",
    "            print_every = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8989b353-4e97-4f24-b49c-b1fb604f9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.load_state_dict(torch.load(\"best-state.pt\"))\n",
    "def prediction(model, loader, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds_all = torch.LongTensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x in loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            output = model.forward(batch_x).to(\"cpu\")\n",
    "            preds_all = torch.cat((preds_all, output), dim=0)\n",
    "    return preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dbd55030-84b9-4588-af31-242123531275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = prediction(model_lstm, dataloaders['valid2'], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "675ebaeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  25.0 %\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i].argmax() == y_val_t[i].argmax():\n",
    "        n += 1\n",
    "print('acc: ',n/len(y_val_t)*100, '%')\n",
    "print(n)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d9fb8-e0fe-4f9f-b646-ddae7a99114c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8cdc4-e954-4a73-b4c9-59ca584522d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e27ce8-7207-4923-b0d4-985f11bff0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
